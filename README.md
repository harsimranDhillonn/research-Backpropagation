# research-Backpropagation
# Artificial Neural Networks’ Learning Algorithm: Backpropagation

Author: Harsimran Dhillon

Abstract:

The performance of the system improves as it becomes trained to recognize event patterns to make decisions. In contrast to the generally dominated traditional approaches to AI such as mathematical and logic-based techniques, neuroscience provides a rich source of inspiration to supplement these techniques with new sorts of algorithms and architectures [Hassabis, 2017]. In Supervised learning, Artificial Neural Networks is a type of machine learning model that is inspired by the neurons found in the Human brain. Learning algorithms are constructed to provide the machine the ability to theoretically learn from previous experiences to improve execution of tasks without requiring an explicitly programmed algorithm for it. 

Backpropagation is a learning algorithm used to train artificial neural networks including multiple layer perceptrons in Supervised learning. This algorithm was reproposed as a learning procedure in 1986 by Rumelhart D.E, Hinton G.E., and Williams R.J. [Rumelhart et al., 1986] which gained it wider recognition. Backpropagation is an efficient algorithm that can improve the accuracy of predictions even where intermediate calculations are performed in the hidden units to contribute to the prediction of an output node’s value.

Full paper:
[Backpropagation Algorithm.pdf](https://github.com/harsimranDhillonn/research-Backpropagation/files/11360628/Backpropagation.Algorithm.pdf)
